{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90253ef-37c2-4d3a-99ff-6e9d8bdd2caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f52d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision as tv\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from src import utils, plots, lossfunc, models, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf629130-0d89-4318-aa50-175906118360",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = torch.nn\n",
    "F = torch.nn.functional\n",
    "tvt = tv.transforms\n",
    "tvd = tv.datasets\n",
    "tu = torch.utils\n",
    "tud = torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f52d1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.set_seed(2022)\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "torch.backends.cudnn.benchmarks = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51d69625-fd48-41c7-acf0-e0bee7760289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "num_classes = 10\n",
    "batch_size = 128\n",
    "train_samples = 45000\n",
    "valid_samples = 5000\n",
    "epochs = 300\n",
    "lr = 0.05\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23492284-d5bf-4807-beed-c2ea4f7cdd9a",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e704408f-ac99-4075-96d5-04dfdb4cd768",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "standardize = tvt.Normalize(\n",
    "    mean = (0.4914, 0.4822, 0.4465),\n",
    "    std = (0.2023, 0.1994, 0.2010)\n",
    ")\n",
    "\n",
    "train_transform = tvt.Compose([\n",
    "    tvt.Resize(32),\n",
    "    tvt.RandomCrop(32, padding=4),\n",
    "    tvt.RandomHorizontalFlip(),\n",
    "    tvt.RandomApply([tvt.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.5),\n",
    "    tvt.RandomGrayscale(p=0.5),\n",
    "    tvt.RandomApply(nn.ModuleList([tvt.RandomRotation((0, 360))]), p=0.5),\n",
    "    tvt.ToTensor(),\n",
    "    standardize,\n",
    "])\n",
    "\n",
    "test_transform = tvt.Compose([\n",
    "    tvt.ToTensor(),\n",
    "    standardize,\n",
    "])\n",
    "\n",
    "# Train\n",
    "train_data = tvd.CIFAR10('/tmp/data', train=True, download=True, transform=train_transform) #50K\n",
    "\n",
    "train, valid = tud.random_split(train_data, [train_samples, valid_samples])\n",
    "\n",
    "train_loader = tud.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
    "\n",
    "valid_loader = tud.DataLoader(valid, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
    "\n",
    "# Test\n",
    "test_data = tvd.CIFAR10('/tmp/data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "test_loader = tud.DataLoader(test_data, batch_size=batch_size, shuffle=True,num_workers=2, pin_memory=True)\n",
    "\n",
    "# OOD\n",
    "fake_data = tvd.FakeData(size=train_samples, image_size=(3, 32, 32),\n",
    "                         num_classes=num_classes, transform=train_transform)\n",
    "\n",
    "fake_loader = tud.DataLoader(fake_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
    "\n",
    "fake_valid_data = tvd.FakeData(size=valid_samples, image_size=(3, 32, 32), num_classes=num_classes, transform=train_transform)\n",
    "\n",
    "fake_valid_loader = tud.DataLoader(fake_valid_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
    "\n",
    "ood_data = tvd.CIFAR100('/tmp/data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "ood_loader = tud.DataLoader(ood_data, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590cd337-24f1-4995-950b-ec861f6884f7",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66413d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-02.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WideResNet28x10(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer1): Sequential(\n",
       "    (0): WideBasic(\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): WideBasic(\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): WideBasic(\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): WideBasic(\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): WideBasic(\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2))\n",
       "      )\n",
       "    )\n",
       "    (1): WideBasic(\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): WideBasic(\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): WideBasic(\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): WideBasic(\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2))\n",
       "      )\n",
       "    )\n",
       "    (1): WideBasic(\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): WideBasic(\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): WideBasic(\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=640, out_features=10, bias=True)\n",
       "  (drop): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "model = models.WideResNet28x10(num_classes=num_classes, dropout_rate=0.25)\n",
    "criterion = lossfunc.contrastive_regularized\n",
    "opt = torch.optim.SGD(model.parameters(), lr, momentum, weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=300, verbose=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb179a7a",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f48a5888",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7297a3957a0d4b3c8c20bbbfc0c797ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tAverage Loss: 3.2577,\tAccuracy: 22.69%,\tCosine: 0.8527\n",
      "Test:\tAverage Loss: 3.4466,\tAccuracy: 23.18%,\tValidation Margin: -0.3363\n",
      "=> Saving a new best, best_valid_acc: 0.23177083333333334\n",
      "Adjusting learning rate of group 0 to 4.9999e-02.\n",
      "Train:\tAverage Loss: 3.1360,\tAccuracy: 27.22%,\tCosine: 0.8147\n",
      "Test:\tAverage Loss: 3.5535,\tAccuracy: 24.70%,\tValidation Margin: -0.5510\n",
      "Adjusting learning rate of group 0 to 4.9995e-02.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[0;32m---> 10\u001b[0m     tr_loss, tr_acc, cos \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mappend(tr_loss), train_acc\u001b[38;5;241m.\u001b[39mappend(tr_acc), cosine\u001b[38;5;241m.\u001b[39mappend(cos)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain:\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mAverage Loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mCosine: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(tr_loss, \u001b[38;5;241m100.0\u001b[39m \u001b[38;5;241m*\u001b[39m tr_acc, cos))\n",
      "File \u001b[0;32m~/RAIOOD/src/utils.py:272\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, opt, data_loader, criterion, device, scheduler)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(samples, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(samples[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 272\u001b[0m         x, y, x_ood, y_ood \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m var: var\u001b[38;5;241m.\u001b[39mto(device), \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain(\u001b[38;5;241m*\u001b[39msamples)))\n\u001b[1;32m    273\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, x_ood], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/RAIOOD/src/utils.py:272\u001b[0m, in \u001b[0;36mtrain.<locals>.<lambda>\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(samples, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(samples[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 272\u001b[0m         x, y, x_ood, y_ood \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m var: \u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain(\u001b[38;5;241m*\u001b[39msamples)))\n\u001b[1;32m    273\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, x_ood], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = [], []\n",
    "valid_loss, valid_acc = [], []\n",
    "margin, cosine = [], []\n",
    "best_val_loss = 0.0\n",
    "data_loader = (train_loader, fake_loader)\n",
    "validation_loader = (valid_loader, fake_valid_loader)\n",
    "\n",
    "# Train\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    tr_loss, tr_acc, cos = utils.train(model, opt, data_loader, criterion, device)\n",
    "    train_loss.append(tr_loss), train_acc.append(tr_acc), cosine.append(cos)\n",
    "    print(\"Train:\\tAverage Loss: {:.4f},\\tAccuracy: {:.2f}%,\\tCosine: {:.4f}\".format(tr_loss, 100.0 * tr_acc, cos))\n",
    "    \n",
    "    val_loss, val_acc, val_margin, _ = utils.test(model, validation_loader, criterion, device)\n",
    "    valid_loss.append(val_loss), valid_acc.append(val_acc), margin.append(val_margin)\n",
    "    print(\"Test:\\tAverage Loss: {:.4f},\\tAccuracy: {:.2f}%,\\tValidation Margin: {:.4f}\".format(val_loss, 100.0 * val_acc, val_margin))\n",
    "    \n",
    "    # Get bool not ByteTensor\n",
    "    is_best = True if epoch == 0 else bool(val_loss < best_val_loss)\n",
    "    \n",
    "    # Get greater Tensor to keep track best acc\n",
    "    operator = max if epoch == 0 else min\n",
    "    best_val_loss = torch.FloatTensor([operator(val_loss, best_val_loss)])\n",
    "    \n",
    "    # Save checkpoint if val_loss is a new best\n",
    "    utils.save_checkpoint({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optim_state_dict': opt.state_dict(),\n",
    "        'valid_accuracy': valid_acc\n",
    "    }, is_best, val_acc, filename='{}_{}_{}_{}.pth.tar'.format(\n",
    "        model.__str__(), \n",
    "        train_data.__class__.__name__, \n",
    "        criterion.__name__, \n",
    "        datetime.now().strftime(\"%d-%m-%Y-%H:%M:%S\")))\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05af640",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6382f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_valid_loss = min(valid_loss)\n",
    "best_epoch, = np.where(np.array(valid_loss) == min_valid_loss)\n",
    "max_valid_acc = valid_acc[best_epoch.item()]\n",
    "plt.plot(range(epochs), train_loss, label='train loss')\n",
    "plt.plot(range(epochs), train_acc, label='train acc')\n",
    "plt.plot(range(epochs), valid_loss, label='valid loss')\n",
    "plt.plot(range(epochs), valid_acc, label='valid acc')\n",
    "plt.plot(range(epochs), margin, label='margin')\n",
    "plt.vlines(best_epoch.item(), ymin=min_valid_loss, ymax=max_valid_acc, colors='black', label='best-valid@{:.2f}%'.format(100.0 * max_valid_acc))\n",
    "plt.title(\"Loss vs Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt = torch.load('./chkpts/WideResNet28x10_CIFAR10_contrastive_regularised_26-12-2022-19:58:52.pth.tar')\n",
    "model.load_state_dict(chkpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3cc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, te_margin, logits_in = utils.test(model, test_loader, lossfunc.cross_entropy, device)\n",
    "print(\"Test:\\tAverage Loss: {:.4f},\\tAccuracy: {:.2f}%,\\tMargin: {:.4f}\".format(loss, 100.0 * acc, te_margin))\n",
    "loss, acc, ood_margin, logits_out = utils.test(model, ood_loader, lossfunc.cross_entropy, device)\n",
    "print(\"Test OoD:\\tAverage Loss: {:.4f},\\tAccuracy: {:.2f}%,\\tMargin: {:.4f}\".format(loss, 100.0 * acc, ood_margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af2c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_in = torch.vstack(logits_in)\n",
    "logits_out = torch.vstack(logits_out)\n",
    "metrics_in = metrics.dirichlet_uncertainty(logits_in.cpu().numpy())\n",
    "metrics_out = metrics.dirichlet_uncertainty(logits_out.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cdf5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = len(logits_in)\n",
    "y_ood = len(logits_out)\n",
    "for string in ['confidence', 'entropy_of_conf', 'mutual_information']:\n",
    "    if string == \"confidence\":\n",
    "        y_true = np.r_[np.ones(y_test), np.zeros(y_ood)]\n",
    "        y_scores = np.r_[metrics_in[string], metrics_out[string]]\n",
    "    else:\n",
    "        y_true = np.r_[np.ones(y_ood), np.zeros(y_test)]\n",
    "        y_scores = np.r_[metrics_out[string], metrics_in[string]]\n",
    "    print(\"ROC values:\\n {} = {},\\n\".format(string, roc_auc_score(y_true, y_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "for i, string in enumerate(['confidence', 'entropy_of_conf', 'mutual_information']):\n",
    "#     ax[i].set_xscale('log')\n",
    "    ax[i].hist(metrics_in[string], bins=np.linspace(0, 3, num=10), label='Test', alpha=0.5)\n",
    "    ax[i].hist(metrics_out[string], bins=np.linspace(0, 3, num=10), label='OoD', alpha=0.5)\n",
    "    ax[i].legend()\n",
    "    ax[i].set_title(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_loader))\n",
    "X, y = X.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ef0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "model.eval()\n",
    "Xi, Yi, Zi = utils.draw_loss(model, X[0:1], y[0:1], device=device)\n",
    "plots.plot_loss(Xi, Yi, Zi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
