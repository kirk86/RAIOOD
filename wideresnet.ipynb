{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f52d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision as tv\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from src import utils, plots, metrics\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f52d1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.set_seed(2022)\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "torch.backends.cudnn.benchmarks = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1469d7b1-960f-4930-88d6-d05860f49f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_transform = tv.transforms.Compose([\n",
    "    tv.transforms.ToTensor(),\n",
    "])\n",
    "dataset = tv.datasets.FashionMNIST('/tmp/data', train=True, download=True, transform=test_transform) # 60\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=10, num_workers=0, shuffle=False)\n",
    "\n",
    "mean = 0.\n",
    "std = 0.\n",
    "for images, _ in loader:\n",
    "    batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "\n",
    "mean /= len(loader.dataset)\n",
    "std /= len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac530f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: /tmp/data/train_32x32.mat\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: /tmp/data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transform, ood_type=None, distance=15, no_jsd=True):\n",
    "        if isinstance(data, tuple):\n",
    "            self.data_in, self.data_ood = data\n",
    "        else:\n",
    "            self.data_in = data\n",
    "        self.ood_type = ood_type\n",
    "        self.distance = distance\n",
    "        self.no_jsd = no_jsd\n",
    "        self.clean = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.data_in[index]\n",
    "        if self.ood_type == 'uniform':\n",
    "            x_tensor = tv.transforms.ToTensor()(x)\n",
    "            x_ood = torch.FloatTensor(x_tensor.shape).uniform_(x_tensor.min() - self.distance, x_tensor.max() + self.distance)\n",
    "            x_ood = tv.transforms.ToPILImage()(x_ood).convert(\"RGB\")\n",
    "            x, x_ood = self.clean(x), self.clean(x_ood) if self.no_jsd else (self.clean(x), self.ood(x_ood), self._ood2(x_ood))\n",
    "            x = (x, x_ood)\n",
    "        elif self.ood_type == 'augmix':\n",
    "            x = (self.clean(x), self.ood(x), self.ood2(x))\n",
    "        elif self.ood_type == 'datafusion':\n",
    "            x_ood, y_ood = self.data_ood[index]\n",
    "            x = (self.clean(x), self.clean(x_ood)) if self.no_jsd else (self.clean(x), self.ood(x_ood), self.ood2(x_ood))\n",
    "        else:\n",
    "            x = self.clean(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_in)\n",
    "\n",
    "# normalize data==============================\n",
    "normalize_cifar10 = tv.transforms.Normalize(\n",
    "    mean=(0.4914, 0.4822, 0.4465),\n",
    "    std=(0.2023, 0.1994, 0.2010)\n",
    ")\n",
    "\n",
    "normalize_cifar100 = tv.transforms.Normalize(\n",
    "    mean=(0.5071, 0.4867, 0.4408),\n",
    "    std=(0.2675, 0.2565, 0.2761)\n",
    ")\n",
    "\n",
    "normalize_svhn = tv.transforms.Normalize(\n",
    "    mean=(0.4376, 0.4437, 0.4728),\n",
    "    std=(0.1980, 0.2010, 0.1970)\n",
    ")\n",
    "\n",
    "normalize_fmnist = tv.transforms.Normalize(\n",
    "    mean=(0.2860, 0.2860, 0.2860),\n",
    "    std=(0.3205, 0.3205, 0.3205)\n",
    ")\n",
    "\n",
    "# normalize data\n",
    "normalize = normalize_svhn\n",
    "\n",
    "test_transform = tv.transforms.Compose([\n",
    "    tv.transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "fmnist_transform = tv.transforms.Compose([\n",
    "#     tv.transforms.Resize((32, 32)),\n",
    "    tv.transforms.Grayscale(num_output_channels=3),\n",
    "])\n",
    "\n",
    "# download train datasets===================================================\n",
    "cifar10 = tv.datasets.CIFAR10('/tmp/data', train=True, download=True) #50K\n",
    "cifar100 = tv.datasets.CIFAR100('/tmp/data', train=True, download=True) # 50K\n",
    "svhn = tv.datasets.SVHN('/tmp/data', split='train', download=True) # 70K\n",
    "fmnist = tv.datasets.FashionMNIST('/tmp/data', train=True, download=True, transform=fmnist_transform) # 60K\n",
    "\n",
    "# download test datasets===================================================\n",
    "cifar10_test = tv.datasets.CIFAR10('/tmp/data', train=False, download=True, transform=test_transform)\n",
    "cifar100_test = tv.datasets.CIFAR100('/tmp/data', train=False, download=True, transform=test_transform)\n",
    "svhn_test = tv.datasets.SVHN('/tmp/data', split='test', download=True, transform=test_transform)\n",
    "fmnist_test = tv.datasets.FashionMNIST('/tmp/data', train=False, download=True, transform=test_transform) # 60K\n",
    "\n",
    "# choose train and test dataset\n",
    "dataset_list = [cifar10, ] * 2\n",
    "cifar10 = torch.utils.data.ConcatDataset(dataset_list)\n",
    "train_data = (svhn, cifar10)\n",
    "train_samples = 60000\n",
    "valid_samples = len(svhn) - train_samples\n",
    "test_data = svhn_test\n",
    "\n",
    "# indomain data augmentations=========================================\n",
    "train_transform = tv.transforms.Compose([\n",
    "    tv.transforms.Resize(32),\n",
    "    tv.transforms.RandomCrop(32, padding=4),\n",
    "    tv.transforms.RandomHorizontalFlip(),\n",
    "    tv.transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# setup dataloaders========================================================\n",
    "transforms = train_transform\n",
    "train_ood_data = torch.utils.data.ConcatDataset([cifar100, svhn, fmnist])\n",
    "dataset = MyDataset(train_data, transforms, ood_type='datafusion')\n",
    "\n",
    "train, valid = torch.utils.data.random_split(dataset, [train_samples, valid_samples])\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95e677e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cifar100_test = torch.utils.data.DataLoader(\n",
    "    tv.datasets.CIFAR100('/tmp/data', train=False, download=True, transform=test_transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66413d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-02.\n"
     ]
    }
   ],
   "source": [
    "from models.wideresnet import WideResNet28x10\n",
    "model = WideResNet28x10(num_classes=10, dropout_rate=0.25)\n",
    "\n",
    "# hyperparams\n",
    "epochs = 300\n",
    "\n",
    "# optim\n",
    "lr = 0.05\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr, momentum, weight_decay)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.95, patience=25, verbose=True)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=300, verbose=True)\n",
    "\n",
    "# def get_lr(step, total_steps, lr_max, lr_min):\n",
    "#     \"\"\"Compute learning rate according to cosine annealing schedule.\"\"\"\n",
    "#     return lr_min + (lr_max - lr_min) * 0.5 * (1 + np.cos(step / total_steps * np.pi))\n",
    "\n",
    "# learning_rate = 0.1\n",
    "# scheduler = torch.optim.lr_scheduler.LambdaLR(opt,\n",
    "#           lr_lambda=lambda step: get_lr(  # pylint: disable=g-long-lambda\n",
    "#           step,\n",
    "#           epochs * len(cifar_train),\n",
    "#           1,  # lr_lambda computes multiplicative factor\n",
    "#           1e-6 / learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb179a7a",
   "metadata": {},
   "source": [
    "### Train Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cca516-784e-4d46-9d06-f37fd658d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine(model, inputs, labels):\n",
    "    model.eval()\n",
    "    inputs = torch.cat(inputs, dim=0).detach()\n",
    "    labels = torch.cat([labels] * 2, dim=0).detach()\n",
    "    logits = model(inputs)\n",
    "    crossent = F.cross_entropy(logits, labels)\n",
    "#     caclulate grad of loss w.r.t. logits\n",
    "    grad = torch.autograd.grad(crossent, logits)[0]\n",
    "    grad_in, grad_ood = grad.detach().chunk(2, dim=0)\n",
    "    cosine = F.cosine_similarity(grad_in, grad_ood, dim=1).mean()\n",
    "    model.train()\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97590786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cosine(model, opt, data_loader, criterion, device):\n",
    "    n_samples, error, correct, = 0.0, 0.0, 0.0\n",
    "    cosine_error, psnr_error = 0.0, 0.0\n",
    "    zero = torch.tensor([0.0]).to(device)\n",
    "    one = torch.tensor([1.0]).to(device)\n",
    "    model.train()\n",
    "    for x, y in data_loader:\n",
    "        x, x_ood, y = map(lambda var: var.to(device), (x[0], x[1], y))\n",
    "        bsize = x.size(0)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        inputs = torch.cat([x, x_ood], dim=0)\n",
    "        logits = model(inputs)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        probs_in, probs_ood = probs.split(bsize)\n",
    "        cosine = F.cosine_similarity(probs_in, probs_ood, dim=1).mean()\n",
    "        logits_in, logits_ood = logits.split(bsize)\n",
    "        xent = criterion(logits_in, y)\n",
    "#         margin = torch.maximum(zero, cosine + one)\n",
    "#         correct_prob = probs_in[range(bsize), y]\n",
    "#         l2 = 0.08 * ((correct_prob - 0.9954)**2).sum()\n",
    "#         l1 = 0.05 * (probs_ood - (1.0/10.0)).abs().sum()\n",
    "    \n",
    "#         loss = margin + l1 + l2\n",
    "        loss = 2 * xent + (-1.0 * cosine)\n",
    "        y_hat = logits_in.max(dim=1)[1]\n",
    "        \n",
    "        correct += y.eq(y_hat.view_as(y)).sum().item()\n",
    "        error += bsize * loss.item()\n",
    "        cosine_error += bsize * cosine.item()\n",
    "#         psnr_error += bsize * l1.item()\n",
    "        n_samples += bsize\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 10.0)\n",
    "        opt.step()\n",
    "#         scheduler.step()\n",
    "    \n",
    "    avg_loss = error / n_samples\n",
    "    avg_acc = correct / n_samples\n",
    "\n",
    "    return avg_loss, avg_acc, cosine_error/n_samples, psnr_error/n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a5888",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5535e1a7cb14928964d8d8ab2c1de0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tAverage Loss: 3.5453,\tAccuracy: 18.59%,\tCosine: 0.9727,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 2.2449,\tAccuracy: 18.55%,\tValidation Margin: -0.1301\n",
      "=> Saving a new best, best_valid_acc: 0.18548691257448896\n",
      "Adjusting learning rate of group 0 to 4.9999e-02.\n",
      "Train:\tAverage Loss: 3.4868,\tAccuracy: 19.21%,\tCosine: 0.9845,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 2.2172,\tAccuracy: 19.97%,\tValidation Margin: -0.1965\n",
      "=> Saving a new best, best_valid_acc: 0.19966809987176587\n",
      "Adjusting learning rate of group 0 to 4.9995e-02.\n",
      "Train:\tAverage Loss: 2.3982,\tAccuracy: 46.02%,\tCosine: 0.6727,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.8087,\tAccuracy: 73.24%,\tValidation Margin: -0.6254\n",
      "=> Saving a new best, best_valid_acc: 0.7324432375348873\n",
      "Adjusting learning rate of group 0 to 4.9988e-02.\n",
      "Train:\tAverage Loss: 0.7585,\tAccuracy: 81.66%,\tCosine: 0.4057,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5966,\tAccuracy: 81.83%,\tValidation Margin: -0.7185\n",
      "=> Saving a new best, best_valid_acc: 0.8182846797918081\n",
      "Adjusting learning rate of group 0 to 4.9978e-02.\n",
      "Train:\tAverage Loss: 0.4314,\tAccuracy: 87.52%,\tCosine: 0.3883,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6065,\tAccuracy: 81.24%,\tValidation Margin: -0.6120\n",
      "Adjusting learning rate of group 0 to 4.9966e-02.\n",
      "Train:\tAverage Loss: 0.3118,\tAccuracy: 89.60%,\tCosine: 0.3808,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4404,\tAccuracy: 86.63%,\tValidation Margin: -0.5287\n",
      "=> Saving a new best, best_valid_acc: 0.8663347665384326\n",
      "Adjusting learning rate of group 0 to 4.9951e-02.\n",
      "Train:\tAverage Loss: 0.2371,\tAccuracy: 90.95%,\tCosine: 0.3785,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3900,\tAccuracy: 88.40%,\tValidation Margin: -0.4818\n",
      "=> Saving a new best, best_valid_acc: 0.8839858188127028\n",
      "Adjusting learning rate of group 0 to 4.9933e-02.\n",
      "Train:\tAverage Loss: 0.1934,\tAccuracy: 91.58%,\tCosine: 0.3761,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3362,\tAccuracy: 90.43%,\tValidation Margin: -0.2965\n",
      "=> Saving a new best, best_valid_acc: 0.9042769857433809\n",
      "Adjusting learning rate of group 0 to 4.9912e-02.\n",
      "Train:\tAverage Loss: 0.1564,\tAccuracy: 92.24%,\tCosine: 0.3743,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3090,\tAccuracy: 90.87%,\tValidation Margin: -0.3423\n",
      "=> Saving a new best, best_valid_acc: 0.9087274647356114\n",
      "Adjusting learning rate of group 0 to 4.9889e-02.\n",
      "Train:\tAverage Loss: 0.1260,\tAccuracy: 92.75%,\tCosine: 0.3720,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3237,\tAccuracy: 91.05%,\tValidation Margin: -0.3477\n",
      "Adjusting learning rate of group 0 to 4.9863e-02.\n",
      "Train:\tAverage Loss: 0.1138,\tAccuracy: 93.09%,\tCosine: 0.3662,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2873,\tAccuracy: 91.62%,\tValidation Margin: -0.3338\n",
      "=> Saving a new best, best_valid_acc: 0.9161952176208795\n",
      "Adjusting learning rate of group 0 to 4.9834e-02.\n",
      "Train:\tAverage Loss: 0.0810,\tAccuracy: 93.54%,\tCosine: 0.3666,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3024,\tAccuracy: 91.53%,\tValidation Margin: -0.3749\n",
      "Adjusting learning rate of group 0 to 4.9803e-02.\n",
      "Train:\tAverage Loss: 0.0734,\tAccuracy: 93.72%,\tCosine: 0.3642,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2631,\tAccuracy: 92.74%,\tValidation Margin: -0.2313\n",
      "=> Saving a new best, best_valid_acc: 0.9274345628724447\n",
      "Adjusting learning rate of group 0 to 4.9769e-02.\n",
      "Train:\tAverage Loss: 0.0455,\tAccuracy: 94.14%,\tCosine: 0.3636,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2655,\tAccuracy: 92.57%,\tValidation Margin: -0.3103\n",
      "Adjusting learning rate of group 0 to 4.9732e-02.\n",
      "Train:\tAverage Loss: 0.0599,\tAccuracy: 94.03%,\tCosine: 0.3598,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3154,\tAccuracy: 91.05%,\tValidation Margin: -0.3894\n",
      "Adjusting learning rate of group 0 to 4.9692e-02.\n",
      "Train:\tAverage Loss: 0.0384,\tAccuracy: 94.28%,\tCosine: 0.3612,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2915,\tAccuracy: 92.36%,\tValidation Margin: -0.3835\n",
      "Adjusting learning rate of group 0 to 4.9650e-02.\n",
      "Train:\tAverage Loss: 0.0124,\tAccuracy: 94.67%,\tCosine: 0.3632,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2494,\tAccuracy: 93.12%,\tValidation Margin: -0.2002\n",
      "=> Saving a new best, best_valid_acc: 0.9312061552387418\n",
      "Adjusting learning rate of group 0 to 4.9605e-02.\n",
      "Train:\tAverage Loss: -0.0047,\tAccuracy: 94.98%,\tCosine: 0.3628,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2609,\tAccuracy: 93.26%,\tValidation Margin: -0.2807\n",
      "Adjusting learning rate of group 0 to 4.9557e-02.\n",
      "Train:\tAverage Loss: -0.0127,\tAccuracy: 95.15%,\tCosine: 0.3624,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2557,\tAccuracy: 92.94%,\tValidation Margin: -0.2438\n",
      "Adjusting learning rate of group 0 to 4.9507e-02.\n",
      "Train:\tAverage Loss: -0.0266,\tAccuracy: 95.29%,\tCosine: 0.3614,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2633,\tAccuracy: 92.81%,\tValidation Margin: -0.2748\n",
      "Adjusting learning rate of group 0 to 4.9454e-02.\n",
      "Train:\tAverage Loss: -0.0402,\tAccuracy: 95.52%,\tCosine: 0.3604,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2487,\tAccuracy: 93.41%,\tValidation Margin: -0.2042\n",
      "=> Saving a new best, best_valid_acc: 0.9341479972844535\n",
      "Adjusting learning rate of group 0 to 4.9398e-02.\n",
      "Train:\tAverage Loss: -0.0445,\tAccuracy: 95.51%,\tCosine: 0.3603,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2344,\tAccuracy: 93.76%,\tValidation Margin: -0.1925\n",
      "=> Saving a new best, best_valid_acc: 0.9376178622614468\n",
      "Adjusting learning rate of group 0 to 4.9339e-02.\n",
      "Train:\tAverage Loss: -0.0584,\tAccuracy: 95.78%,\tCosine: 0.3595,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2726,\tAccuracy: 92.61%,\tValidation Margin: -0.3043\n",
      "Adjusting learning rate of group 0 to 4.9278e-02.\n",
      "Train:\tAverage Loss: -0.0702,\tAccuracy: 95.95%,\tCosine: 0.3581,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2493,\tAccuracy: 93.08%,\tValidation Margin: -0.2492\n",
      "Adjusting learning rate of group 0 to 4.9215e-02.\n",
      "Train:\tAverage Loss: -0.0735,\tAccuracy: 96.01%,\tCosine: 0.3578,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2258,\tAccuracy: 94.00%,\tValidation Margin: -0.1340\n",
      "=> Saving a new best, best_valid_acc: 0.939956249528551\n",
      "Adjusting learning rate of group 0 to 4.9148e-02.\n",
      "Train:\tAverage Loss: -0.0819,\tAccuracy: 96.09%,\tCosine: 0.3572,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2465,\tAccuracy: 93.71%,\tValidation Margin: -0.2187\n",
      "Adjusting learning rate of group 0 to 4.9079e-02.\n",
      "Train:\tAverage Loss: -0.0937,\tAccuracy: 96.27%,\tCosine: 0.3565,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2900,\tAccuracy: 92.13%,\tValidation Margin: -0.2781\n",
      "Adjusting learning rate of group 0 to 4.9007e-02.\n",
      "Train:\tAverage Loss: -0.1076,\tAccuracy: 96.55%,\tCosine: 0.3554,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2505,\tAccuracy: 93.48%,\tValidation Margin: -0.2341\n",
      "Adjusting learning rate of group 0 to 4.8933e-02.\n",
      "Train:\tAverage Loss: -0.1105,\tAccuracy: 96.54%,\tCosine: 0.3551,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2447,\tAccuracy: 93.84%,\tValidation Margin: -0.2041\n",
      "Adjusting learning rate of group 0 to 4.8856e-02.\n",
      "Train:\tAverage Loss: -0.1210,\tAccuracy: 96.69%,\tCosine: 0.3541,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2449,\tAccuracy: 93.57%,\tValidation Margin: -0.1625\n",
      "Adjusting learning rate of group 0 to 4.8776e-02.\n",
      "Train:\tAverage Loss: -0.1227,\tAccuracy: 96.76%,\tCosine: 0.3542,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2332,\tAccuracy: 93.81%,\tValidation Margin: -0.1749\n",
      "Adjusting learning rate of group 0 to 4.8694e-02.\n",
      "Train:\tAverage Loss: -0.1318,\tAccuracy: 96.88%,\tCosine: 0.3536,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2429,\tAccuracy: 94.03%,\tValidation Margin: -0.1904\n",
      "Adjusting learning rate of group 0 to 4.8609e-02.\n",
      "Train:\tAverage Loss: -0.1384,\tAccuracy: 96.92%,\tCosine: 0.3532,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2638,\tAccuracy: 93.55%,\tValidation Margin: -0.2778\n",
      "Adjusting learning rate of group 0 to 4.8522e-02.\n",
      "Train:\tAverage Loss: -0.1439,\tAccuracy: 97.06%,\tCosine: 0.3527,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2534,\tAccuracy: 93.58%,\tValidation Margin: -0.2422\n",
      "Adjusting learning rate of group 0 to 4.8432e-02.\n",
      "Train:\tAverage Loss: -0.1465,\tAccuracy: 97.03%,\tCosine: 0.3524,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2644,\tAccuracy: 93.76%,\tValidation Margin: -0.2601\n",
      "Adjusting learning rate of group 0 to 4.8340e-02.\n",
      "Train:\tAverage Loss: -0.1605,\tAccuracy: 97.30%,\tCosine: 0.3511,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2726,\tAccuracy: 93.02%,\tValidation Margin: -0.3054\n",
      "Adjusting learning rate of group 0 to 4.8244e-02.\n",
      "Train:\tAverage Loss: -0.1644,\tAccuracy: 97.26%,\tCosine: 0.3512,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2517,\tAccuracy: 93.32%,\tValidation Margin: -0.2135\n",
      "Adjusting learning rate of group 0 to 4.8147e-02.\n",
      "Train:\tAverage Loss: -0.1680,\tAccuracy: 97.34%,\tCosine: 0.3509,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2769,\tAccuracy: 93.41%,\tValidation Margin: -0.2974\n",
      "Adjusting learning rate of group 0 to 4.8047e-02.\n",
      "Train:\tAverage Loss: -0.1719,\tAccuracy: 97.42%,\tCosine: 0.3511,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2616,\tAccuracy: 94.15%,\tValidation Margin: -0.2360\n",
      "Adjusting learning rate of group 0 to 4.7944e-02.\n",
      "Train:\tAverage Loss: -0.1802,\tAccuracy: 97.56%,\tCosine: 0.3494,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2897,\tAccuracy: 93.59%,\tValidation Margin: -0.3317\n",
      "Adjusting learning rate of group 0 to 4.7839e-02.\n",
      "Train:\tAverage Loss: -0.1898,\tAccuracy: 97.68%,\tCosine: 0.3495,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2791,\tAccuracy: 94.02%,\tValidation Margin: -0.2786\n",
      "Adjusting learning rate of group 0 to 4.7731e-02.\n",
      "Train:\tAverage Loss: -0.1927,\tAccuracy: 97.64%,\tCosine: 0.3493,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3073,\tAccuracy: 92.95%,\tValidation Margin: -0.3902\n",
      "Adjusting learning rate of group 0 to 4.7621e-02.\n",
      "Train:\tAverage Loss: -0.1930,\tAccuracy: 97.67%,\tCosine: 0.3489,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2860,\tAccuracy: 93.31%,\tValidation Margin: -0.3603\n",
      "Adjusting learning rate of group 0 to 4.7508e-02.\n",
      "Train:\tAverage Loss: -0.1975,\tAccuracy: 97.69%,\tCosine: 0.3491,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2938,\tAccuracy: 93.69%,\tValidation Margin: -0.3065\n",
      "Adjusting learning rate of group 0 to 4.7393e-02.\n",
      "Train:\tAverage Loss: -0.2075,\tAccuracy: 97.92%,\tCosine: 0.3485,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2772,\tAccuracy: 93.37%,\tValidation Margin: -0.2296\n",
      "Adjusting learning rate of group 0 to 4.7275e-02.\n",
      "Train:\tAverage Loss: -0.2143,\tAccuracy: 97.97%,\tCosine: 0.3480,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2655,\tAccuracy: 94.19%,\tValidation Margin: -0.2326\n",
      "Adjusting learning rate of group 0 to 4.7155e-02.\n",
      "Train:\tAverage Loss: -0.2106,\tAccuracy: 97.99%,\tCosine: 0.3480,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2593,\tAccuracy: 93.65%,\tValidation Margin: -0.2272\n",
      "Adjusting learning rate of group 0 to 4.7033e-02.\n",
      "Train:\tAverage Loss: -0.2206,\tAccuracy: 98.07%,\tCosine: 0.3476,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2799,\tAccuracy: 93.73%,\tValidation Margin: -0.3125\n",
      "Adjusting learning rate of group 0 to 4.6908e-02.\n",
      "Train:\tAverage Loss: -0.2226,\tAccuracy: 98.09%,\tCosine: 0.3472,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2954,\tAccuracy: 93.37%,\tValidation Margin: -0.3459\n",
      "Adjusting learning rate of group 0 to 4.6780e-02.\n",
      "Train:\tAverage Loss: -0.2305,\tAccuracy: 98.20%,\tCosine: 0.3471,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2944,\tAccuracy: 93.67%,\tValidation Margin: -0.2777\n",
      "Adjusting learning rate of group 0 to 4.6651e-02.\n",
      "Train:\tAverage Loss: -0.2268,\tAccuracy: 98.11%,\tCosine: 0.3472,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2992,\tAccuracy: 93.87%,\tValidation Margin: -0.3161\n",
      "Adjusting learning rate of group 0 to 4.6519e-02.\n",
      "Train:\tAverage Loss: -0.2333,\tAccuracy: 98.24%,\tCosine: 0.3467,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2614,\tAccuracy: 94.34%,\tValidation Margin: -0.1236\n",
      "Adjusting learning rate of group 0 to 4.6384e-02.\n",
      "Train:\tAverage Loss: -0.2413,\tAccuracy: 98.39%,\tCosine: 0.3464,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2974,\tAccuracy: 93.36%,\tValidation Margin: -0.3214\n",
      "Adjusting learning rate of group 0 to 4.6247e-02.\n",
      "Train:\tAverage Loss: -0.2462,\tAccuracy: 98.43%,\tCosine: 0.3461,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2784,\tAccuracy: 94.34%,\tValidation Margin: -0.1969\n",
      "Adjusting learning rate of group 0 to 4.6108e-02.\n",
      "Train:\tAverage Loss: -0.2470,\tAccuracy: 98.48%,\tCosine: 0.3458,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2877,\tAccuracy: 94.17%,\tValidation Margin: -0.2435\n",
      "Adjusting learning rate of group 0 to 4.5967e-02.\n",
      "Train:\tAverage Loss: -0.2441,\tAccuracy: 98.41%,\tCosine: 0.3459,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2704,\tAccuracy: 93.95%,\tValidation Margin: -0.2457\n",
      "Adjusting learning rate of group 0 to 4.5823e-02.\n",
      "Train:\tAverage Loss: -0.2485,\tAccuracy: 98.47%,\tCosine: 0.3456,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3017,\tAccuracy: 93.80%,\tValidation Margin: -0.3099\n",
      "Adjusting learning rate of group 0 to 4.5677e-02.\n",
      "Train:\tAverage Loss: -0.2535,\tAccuracy: 98.56%,\tCosine: 0.3458,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2996,\tAccuracy: 93.29%,\tValidation Margin: -0.3435\n",
      "Adjusting learning rate of group 0 to 4.5529e-02.\n",
      "Train:\tAverage Loss: -0.2568,\tAccuracy: 98.63%,\tCosine: 0.3454,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2927,\tAccuracy: 93.94%,\tValidation Margin: -0.2976\n",
      "Adjusting learning rate of group 0 to 4.5378e-02.\n",
      "Train:\tAverage Loss: -0.2573,\tAccuracy: 98.61%,\tCosine: 0.3456,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3044,\tAccuracy: 94.06%,\tValidation Margin: -0.2356\n",
      "Adjusting learning rate of group 0 to 4.5225e-02.\n",
      "Train:\tAverage Loss: -0.2636,\tAccuracy: 98.69%,\tCosine: 0.3453,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2892,\tAccuracy: 94.06%,\tValidation Margin: -0.2228\n",
      "Adjusting learning rate of group 0 to 4.5070e-02.\n",
      "Train:\tAverage Loss: -0.2678,\tAccuracy: 98.80%,\tCosine: 0.3447,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2898,\tAccuracy: 93.57%,\tValidation Margin: -0.2867\n",
      "Adjusting learning rate of group 0 to 4.4913e-02.\n",
      "Train:\tAverage Loss: -0.2654,\tAccuracy: 98.79%,\tCosine: 0.3447,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.2888,\tAccuracy: 93.91%,\tValidation Margin: -0.2638\n",
      "Adjusting learning rate of group 0 to 4.4754e-02.\n",
      "Train:\tAverage Loss: -0.2714,\tAccuracy: 98.84%,\tCosine: 0.3451,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3047,\tAccuracy: 94.21%,\tValidation Margin: -0.2185\n",
      "Adjusting learning rate of group 0 to 4.4592e-02.\n",
      "Train:\tAverage Loss: -0.2686,\tAccuracy: 98.80%,\tCosine: 0.3446,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3146,\tAccuracy: 94.14%,\tValidation Margin: -0.2862\n",
      "Adjusting learning rate of group 0 to 4.4429e-02.\n",
      "Train:\tAverage Loss: -0.2710,\tAccuracy: 98.80%,\tCosine: 0.3448,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3345,\tAccuracy: 93.83%,\tValidation Margin: -0.3951\n",
      "Adjusting learning rate of group 0 to 4.4263e-02.\n",
      "Train:\tAverage Loss: -0.2732,\tAccuracy: 98.85%,\tCosine: 0.3446,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3136,\tAccuracy: 94.09%,\tValidation Margin: -0.2612\n",
      "Adjusting learning rate of group 0 to 4.4095e-02.\n",
      "Train:\tAverage Loss: -0.2796,\tAccuracy: 98.89%,\tCosine: 0.3449,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3490,\tAccuracy: 92.25%,\tValidation Margin: -0.4234\n",
      "Adjusting learning rate of group 0 to 4.3925e-02.\n",
      "Train:\tAverage Loss: -0.2823,\tAccuracy: 99.02%,\tCosine: 0.3441,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3367,\tAccuracy: 93.92%,\tValidation Margin: -0.3283\n",
      "Adjusting learning rate of group 0 to 4.3753e-02.\n",
      "Train:\tAverage Loss: -0.2855,\tAccuracy: 99.06%,\tCosine: 0.3443,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3534,\tAccuracy: 92.88%,\tValidation Margin: -0.4564\n",
      "Adjusting learning rate of group 0 to 4.3579e-02.\n",
      "Train:\tAverage Loss: -0.2846,\tAccuracy: 99.07%,\tCosine: 0.3442,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3328,\tAccuracy: 94.30%,\tValidation Margin: -0.2342\n",
      "Adjusting learning rate of group 0 to 4.3402e-02.\n",
      "Train:\tAverage Loss: -0.2883,\tAccuracy: 99.12%,\tCosine: 0.3443,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3220,\tAccuracy: 94.15%,\tValidation Margin: -0.2784\n",
      "Adjusting learning rate of group 0 to 4.3224e-02.\n",
      "Train:\tAverage Loss: -0.2925,\tAccuracy: 99.12%,\tCosine: 0.3441,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3594,\tAccuracy: 93.56%,\tValidation Margin: -0.4483\n",
      "Adjusting learning rate of group 0 to 4.3044e-02.\n",
      "Train:\tAverage Loss: -0.2911,\tAccuracy: 99.07%,\tCosine: 0.3440,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3671,\tAccuracy: 93.78%,\tValidation Margin: -0.4257\n",
      "Adjusting learning rate of group 0 to 4.2862e-02.\n",
      "Train:\tAverage Loss: -0.2897,\tAccuracy: 99.11%,\tCosine: 0.3445,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3669,\tAccuracy: 93.45%,\tValidation Margin: -0.4644\n",
      "Adjusting learning rate of group 0 to 4.2678e-02.\n",
      "Train:\tAverage Loss: -0.2955,\tAccuracy: 99.23%,\tCosine: 0.3444,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3391,\tAccuracy: 94.21%,\tValidation Margin: -0.3357\n",
      "Adjusting learning rate of group 0 to 4.2492e-02.\n",
      "Train:\tAverage Loss: -0.2979,\tAccuracy: 99.28%,\tCosine: 0.3442,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3585,\tAccuracy: 93.94%,\tValidation Margin: -0.3543\n",
      "Adjusting learning rate of group 0 to 4.2304e-02.\n",
      "Train:\tAverage Loss: -0.2962,\tAccuracy: 99.23%,\tCosine: 0.3441,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3474,\tAccuracy: 93.78%,\tValidation Margin: -0.3870\n",
      "Adjusting learning rate of group 0 to 4.2114e-02.\n",
      "Train:\tAverage Loss: -0.3005,\tAccuracy: 99.25%,\tCosine: 0.3440,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3330,\tAccuracy: 94.15%,\tValidation Margin: -0.2701\n",
      "Adjusting learning rate of group 0 to 4.1922e-02.\n",
      "Train:\tAverage Loss: -0.2997,\tAccuracy: 99.22%,\tCosine: 0.3443,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3477,\tAccuracy: 94.14%,\tValidation Margin: -0.2964\n",
      "Adjusting learning rate of group 0 to 4.1728e-02.\n",
      "Train:\tAverage Loss: -0.2982,\tAccuracy: 99.27%,\tCosine: 0.3446,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3331,\tAccuracy: 94.17%,\tValidation Margin: -0.2567\n",
      "Adjusting learning rate of group 0 to 4.1533e-02.\n",
      "Train:\tAverage Loss: -0.3008,\tAccuracy: 99.26%,\tCosine: 0.3441,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3539,\tAccuracy: 93.78%,\tValidation Margin: -0.3667\n",
      "Adjusting learning rate of group 0 to 4.1336e-02.\n",
      "Train:\tAverage Loss: -0.3019,\tAccuracy: 99.29%,\tCosine: 0.3446,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3137,\tAccuracy: 94.09%,\tValidation Margin: -0.2733\n",
      "Adjusting learning rate of group 0 to 4.1136e-02.\n",
      "Train:\tAverage Loss: -0.3091,\tAccuracy: 99.43%,\tCosine: 0.3441,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3329,\tAccuracy: 94.54%,\tValidation Margin: -0.1913\n",
      "Adjusting learning rate of group 0 to 4.0936e-02.\n",
      "Train:\tAverage Loss: -0.3120,\tAccuracy: 99.52%,\tCosine: 0.3443,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3650,\tAccuracy: 94.12%,\tValidation Margin: -0.3638\n",
      "Adjusting learning rate of group 0 to 4.0733e-02.\n",
      "Train:\tAverage Loss: -0.3077,\tAccuracy: 99.39%,\tCosine: 0.3443,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3656,\tAccuracy: 94.19%,\tValidation Margin: -0.3572\n",
      "Adjusting learning rate of group 0 to 4.0529e-02.\n",
      "Train:\tAverage Loss: -0.3054,\tAccuracy: 99.39%,\tCosine: 0.3444,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3928,\tAccuracy: 94.04%,\tValidation Margin: -0.4014\n",
      "Adjusting learning rate of group 0 to 4.0323e-02.\n",
      "Train:\tAverage Loss: -0.3113,\tAccuracy: 99.48%,\tCosine: 0.3445,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3847,\tAccuracy: 94.01%,\tValidation Margin: -0.4045\n",
      "Adjusting learning rate of group 0 to 4.0115e-02.\n",
      "Train:\tAverage Loss: -0.3093,\tAccuracy: 99.41%,\tCosine: 0.3447,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3539,\tAccuracy: 94.06%,\tValidation Margin: -0.3156\n",
      "Adjusting learning rate of group 0 to 3.9906e-02.\n",
      "Train:\tAverage Loss: -0.3131,\tAccuracy: 99.49%,\tCosine: 0.3448,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3472,\tAccuracy: 93.91%,\tValidation Margin: -0.3260\n",
      "Adjusting learning rate of group 0 to 3.9695e-02.\n",
      "Train:\tAverage Loss: -0.3166,\tAccuracy: 99.57%,\tCosine: 0.3446,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3550,\tAccuracy: 94.70%,\tValidation Margin: -0.1815\n",
      "Adjusting learning rate of group 0 to 3.9482e-02.\n",
      "Train:\tAverage Loss: -0.3175,\tAccuracy: 99.56%,\tCosine: 0.3449,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3624,\tAccuracy: 94.40%,\tValidation Margin: -0.2236\n",
      "Adjusting learning rate of group 0 to 3.9268e-02.\n",
      "Train:\tAverage Loss: -0.3201,\tAccuracy: 99.57%,\tCosine: 0.3454,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3821,\tAccuracy: 94.21%,\tValidation Margin: -0.3301\n",
      "Adjusting learning rate of group 0 to 3.9052e-02.\n",
      "Train:\tAverage Loss: -0.3233,\tAccuracy: 99.63%,\tCosine: 0.3452,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3634,\tAccuracy: 94.74%,\tValidation Margin: -0.1786\n",
      "Adjusting learning rate of group 0 to 3.8835e-02.\n",
      "Train:\tAverage Loss: -0.3202,\tAccuracy: 99.61%,\tCosine: 0.3457,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3954,\tAccuracy: 93.80%,\tValidation Margin: -0.4251\n",
      "Adjusting learning rate of group 0 to 3.8616e-02.\n",
      "Train:\tAverage Loss: -0.3223,\tAccuracy: 99.58%,\tCosine: 0.3459,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3711,\tAccuracy: 94.14%,\tValidation Margin: -0.3234\n",
      "Adjusting learning rate of group 0 to 3.8396e-02.\n",
      "Train:\tAverage Loss: -0.3218,\tAccuracy: 99.61%,\tCosine: 0.3458,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3700,\tAccuracy: 94.52%,\tValidation Margin: -0.2424\n",
      "Adjusting learning rate of group 0 to 3.8174e-02.\n",
      "Train:\tAverage Loss: -0.3241,\tAccuracy: 99.64%,\tCosine: 0.3460,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4151,\tAccuracy: 93.77%,\tValidation Margin: -0.4979\n",
      "Adjusting learning rate of group 0 to 3.7951e-02.\n",
      "Train:\tAverage Loss: -0.3183,\tAccuracy: 99.57%,\tCosine: 0.3459,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4247,\tAccuracy: 94.24%,\tValidation Margin: -0.3804\n",
      "Adjusting learning rate of group 0 to 3.7726e-02.\n",
      "Train:\tAverage Loss: -0.3248,\tAccuracy: 99.63%,\tCosine: 0.3461,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4281,\tAccuracy: 93.91%,\tValidation Margin: -0.4355\n",
      "Adjusting learning rate of group 0 to 3.7500e-02.\n",
      "Train:\tAverage Loss: -0.3240,\tAccuracy: 99.66%,\tCosine: 0.3466,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4122,\tAccuracy: 94.00%,\tValidation Margin: -0.4093\n",
      "Adjusting learning rate of group 0 to 3.7273e-02.\n",
      "Train:\tAverage Loss: -0.3232,\tAccuracy: 99.64%,\tCosine: 0.3465,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3814,\tAccuracy: 94.40%,\tValidation Margin: -0.2926\n",
      "Adjusting learning rate of group 0 to 3.7044e-02.\n",
      "Train:\tAverage Loss: -0.3238,\tAccuracy: 99.63%,\tCosine: 0.3472,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4016,\tAccuracy: 94.51%,\tValidation Margin: -0.2925\n",
      "Adjusting learning rate of group 0 to 3.6814e-02.\n",
      "Train:\tAverage Loss: -0.3277,\tAccuracy: 99.69%,\tCosine: 0.3475,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3899,\tAccuracy: 94.45%,\tValidation Margin: -0.2762\n",
      "Adjusting learning rate of group 0 to 3.6582e-02.\n",
      "Train:\tAverage Loss: -0.3299,\tAccuracy: 99.71%,\tCosine: 0.3477,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4210,\tAccuracy: 94.18%,\tValidation Margin: -0.4139\n",
      "Adjusting learning rate of group 0 to 3.6350e-02.\n",
      "Train:\tAverage Loss: -0.3314,\tAccuracy: 99.74%,\tCosine: 0.3479,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4176,\tAccuracy: 94.43%,\tValidation Margin: -0.2929\n",
      "Adjusting learning rate of group 0 to 3.6116e-02.\n",
      "Train:\tAverage Loss: -0.3299,\tAccuracy: 99.72%,\tCosine: 0.3485,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4165,\tAccuracy: 94.33%,\tValidation Margin: -0.3097\n",
      "Adjusting learning rate of group 0 to 3.5881e-02.\n",
      "Train:\tAverage Loss: -0.3363,\tAccuracy: 99.80%,\tCosine: 0.3489,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4579,\tAccuracy: 93.68%,\tValidation Margin: -0.4819\n",
      "Adjusting learning rate of group 0 to 3.5644e-02.\n",
      "Train:\tAverage Loss: -0.3340,\tAccuracy: 99.75%,\tCosine: 0.3494,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4576,\tAccuracy: 93.87%,\tValidation Margin: -0.4916\n",
      "Adjusting learning rate of group 0 to 3.5407e-02.\n",
      "Train:\tAverage Loss: -0.3297,\tAccuracy: 99.70%,\tCosine: 0.3494,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4158,\tAccuracy: 94.21%,\tValidation Margin: -0.4191\n",
      "Adjusting learning rate of group 0 to 3.5168e-02.\n",
      "Train:\tAverage Loss: -0.3347,\tAccuracy: 99.76%,\tCosine: 0.3499,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4198,\tAccuracy: 94.52%,\tValidation Margin: -0.3008\n",
      "Adjusting learning rate of group 0 to 3.4929e-02.\n",
      "Train:\tAverage Loss: -0.3347,\tAccuracy: 99.74%,\tCosine: 0.3503,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4232,\tAccuracy: 94.24%,\tValidation Margin: -0.3835\n",
      "Adjusting learning rate of group 0 to 3.4688e-02.\n",
      "Train:\tAverage Loss: -0.3397,\tAccuracy: 99.83%,\tCosine: 0.3512,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4424,\tAccuracy: 94.21%,\tValidation Margin: -0.4116\n",
      "Adjusting learning rate of group 0 to 3.4446e-02.\n",
      "Train:\tAverage Loss: -0.3344,\tAccuracy: 99.72%,\tCosine: 0.3513,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4545,\tAccuracy: 94.34%,\tValidation Margin: -0.4028\n",
      "Adjusting learning rate of group 0 to 3.4203e-02.\n",
      "Train:\tAverage Loss: -0.3351,\tAccuracy: 99.74%,\tCosine: 0.3516,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.3996,\tAccuracy: 94.70%,\tValidation Margin: -0.2080\n",
      "Adjusting learning rate of group 0 to 3.3959e-02.\n",
      "Train:\tAverage Loss: -0.3425,\tAccuracy: 99.86%,\tCosine: 0.3526,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4372,\tAccuracy: 94.72%,\tValidation Margin: -0.2281\n",
      "Adjusting learning rate of group 0 to 3.3714e-02.\n",
      "Train:\tAverage Loss: -0.3441,\tAccuracy: 99.84%,\tCosine: 0.3534,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4306,\tAccuracy: 94.40%,\tValidation Margin: -0.3538\n",
      "Adjusting learning rate of group 0 to 3.3468e-02.\n",
      "Train:\tAverage Loss: -0.3422,\tAccuracy: 99.82%,\tCosine: 0.3539,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4160,\tAccuracy: 94.39%,\tValidation Margin: -0.3622\n",
      "Adjusting learning rate of group 0 to 3.3222e-02.\n",
      "Train:\tAverage Loss: -0.3416,\tAccuracy: 99.78%,\tCosine: 0.3540,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4280,\tAccuracy: 94.58%,\tValidation Margin: -0.3025\n",
      "Adjusting learning rate of group 0 to 3.2974e-02.\n",
      "Train:\tAverage Loss: -0.3437,\tAccuracy: 99.80%,\tCosine: 0.3552,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4133,\tAccuracy: 94.44%,\tValidation Margin: -0.3140\n",
      "Adjusting learning rate of group 0 to 3.2725e-02.\n",
      "Train:\tAverage Loss: -0.3471,\tAccuracy: 99.86%,\tCosine: 0.3559,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4037,\tAccuracy: 94.91%,\tValidation Margin: -0.0463\n",
      "Adjusting learning rate of group 0 to 3.2476e-02.\n",
      "Train:\tAverage Loss: -0.3518,\tAccuracy: 99.90%,\tCosine: 0.3579,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4354,\tAccuracy: 94.79%,\tValidation Margin: -0.1630\n",
      "Adjusting learning rate of group 0 to 3.2226e-02.\n",
      "Train:\tAverage Loss: -0.3493,\tAccuracy: 99.86%,\tCosine: 0.3580,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4494,\tAccuracy: 94.68%,\tValidation Margin: -0.2185\n",
      "Adjusting learning rate of group 0 to 3.1975e-02.\n",
      "Train:\tAverage Loss: -0.3514,\tAccuracy: 99.88%,\tCosine: 0.3588,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4270,\tAccuracy: 95.20%,\tValidation Margin: 0.1135\n",
      "Adjusting learning rate of group 0 to 3.1723e-02.\n",
      "Train:\tAverage Loss: -0.3507,\tAccuracy: 99.88%,\tCosine: 0.3591,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4434,\tAccuracy: 94.79%,\tValidation Margin: -0.1259\n",
      "Adjusting learning rate of group 0 to 3.1470e-02.\n",
      "Train:\tAverage Loss: -0.3526,\tAccuracy: 99.87%,\tCosine: 0.3602,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4508,\tAccuracy: 94.77%,\tValidation Margin: -0.2150\n",
      "Adjusting learning rate of group 0 to 3.1217e-02.\n",
      "Train:\tAverage Loss: -0.3519,\tAccuracy: 99.85%,\tCosine: 0.3608,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4533,\tAccuracy: 94.44%,\tValidation Margin: -0.3714\n",
      "Adjusting learning rate of group 0 to 3.0963e-02.\n",
      "Train:\tAverage Loss: -0.3559,\tAccuracy: 99.90%,\tCosine: 0.3624,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4778,\tAccuracy: 94.49%,\tValidation Margin: -0.3678\n",
      "Adjusting learning rate of group 0 to 3.0709e-02.\n",
      "Train:\tAverage Loss: -0.3544,\tAccuracy: 99.87%,\tCosine: 0.3628,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4880,\tAccuracy: 94.73%,\tValidation Margin: -0.2213\n",
      "Adjusting learning rate of group 0 to 3.0454e-02.\n",
      "Train:\tAverage Loss: -0.3543,\tAccuracy: 99.85%,\tCosine: 0.3634,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4813,\tAccuracy: 94.47%,\tValidation Margin: -0.4098\n",
      "Adjusting learning rate of group 0 to 3.0198e-02.\n",
      "Train:\tAverage Loss: -0.3570,\tAccuracy: 99.86%,\tCosine: 0.3649,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5026,\tAccuracy: 94.34%,\tValidation Margin: -0.3721\n",
      "Adjusting learning rate of group 0 to 2.9941e-02.\n",
      "Train:\tAverage Loss: -0.3571,\tAccuracy: 99.87%,\tCosine: 0.3654,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4969,\tAccuracy: 94.59%,\tValidation Margin: -0.3240\n",
      "Adjusting learning rate of group 0 to 2.9685e-02.\n",
      "Train:\tAverage Loss: -0.3616,\tAccuracy: 99.90%,\tCosine: 0.3673,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4527,\tAccuracy: 94.91%,\tValidation Margin: -0.0740\n",
      "Adjusting learning rate of group 0 to 2.9427e-02.\n",
      "Train:\tAverage Loss: -0.3626,\tAccuracy: 99.91%,\tCosine: 0.3687,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5017,\tAccuracy: 94.69%,\tValidation Margin: -0.2630\n",
      "Adjusting learning rate of group 0 to 2.9169e-02.\n",
      "Train:\tAverage Loss: -0.3594,\tAccuracy: 99.84%,\tCosine: 0.3690,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4889,\tAccuracy: 94.52%,\tValidation Margin: -0.4015\n",
      "Adjusting learning rate of group 0 to 2.8911e-02.\n",
      "Train:\tAverage Loss: -0.3620,\tAccuracy: 99.90%,\tCosine: 0.3696,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4775,\tAccuracy: 94.61%,\tValidation Margin: -0.3545\n",
      "Adjusting learning rate of group 0 to 2.8652e-02.\n",
      "Train:\tAverage Loss: -0.3650,\tAccuracy: 99.91%,\tCosine: 0.3713,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4863,\tAccuracy: 94.83%,\tValidation Margin: -0.1548\n",
      "Adjusting learning rate of group 0 to 2.8393e-02.\n",
      "Train:\tAverage Loss: -0.3661,\tAccuracy: 99.91%,\tCosine: 0.3722,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4785,\tAccuracy: 94.78%,\tValidation Margin: -0.1558\n",
      "Adjusting learning rate of group 0 to 2.8133e-02.\n",
      "Train:\tAverage Loss: -0.3681,\tAccuracy: 99.91%,\tCosine: 0.3744,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4753,\tAccuracy: 94.58%,\tValidation Margin: -0.2888\n",
      "Adjusting learning rate of group 0 to 2.7873e-02.\n",
      "Train:\tAverage Loss: -0.3706,\tAccuracy: 99.94%,\tCosine: 0.3752,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4697,\tAccuracy: 94.86%,\tValidation Margin: -0.1073\n",
      "Adjusting learning rate of group 0 to 2.7613e-02.\n",
      "Train:\tAverage Loss: -0.3756,\tAccuracy: 99.95%,\tCosine: 0.3793,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4947,\tAccuracy: 94.77%,\tValidation Margin: -0.1930\n",
      "Adjusting learning rate of group 0 to 2.7353e-02.\n",
      "Train:\tAverage Loss: -0.3764,\tAccuracy: 99.94%,\tCosine: 0.3799,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4890,\tAccuracy: 94.96%,\tValidation Margin: -0.0306\n",
      "Adjusting learning rate of group 0 to 2.7092e-02.\n",
      "Train:\tAverage Loss: -0.3779,\tAccuracy: 99.94%,\tCosine: 0.3818,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4987,\tAccuracy: 94.79%,\tValidation Margin: -0.1683\n",
      "Adjusting learning rate of group 0 to 2.6831e-02.\n",
      "Train:\tAverage Loss: -0.3797,\tAccuracy: 99.95%,\tCosine: 0.3830,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.4947,\tAccuracy: 94.83%,\tValidation Margin: -0.1845\n",
      "Adjusting learning rate of group 0 to 2.6570e-02.\n",
      "Train:\tAverage Loss: -0.3810,\tAccuracy: 99.95%,\tCosine: 0.3848,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5149,\tAccuracy: 94.65%,\tValidation Margin: -0.3072\n",
      "Adjusting learning rate of group 0 to 2.6308e-02.\n",
      "Train:\tAverage Loss: -0.3817,\tAccuracy: 99.92%,\tCosine: 0.3870,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5280,\tAccuracy: 94.81%,\tValidation Margin: -0.1525\n",
      "Adjusting learning rate of group 0 to 2.6047e-02.\n",
      "Train:\tAverage Loss: -0.3833,\tAccuracy: 99.93%,\tCosine: 0.3881,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5097,\tAccuracy: 94.63%,\tValidation Margin: -0.2431\n",
      "Adjusting learning rate of group 0 to 2.5785e-02.\n",
      "Train:\tAverage Loss: -0.3824,\tAccuracy: 99.93%,\tCosine: 0.3877,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5039,\tAccuracy: 94.84%,\tValidation Margin: -0.1335\n",
      "Adjusting learning rate of group 0 to 2.5524e-02.\n",
      "Train:\tAverage Loss: -0.3847,\tAccuracy: 99.93%,\tCosine: 0.3892,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5160,\tAccuracy: 94.70%,\tValidation Margin: -0.2620\n",
      "Adjusting learning rate of group 0 to 2.5262e-02.\n",
      "Train:\tAverage Loss: -0.3866,\tAccuracy: 99.93%,\tCosine: 0.3914,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5112,\tAccuracy: 94.66%,\tValidation Margin: -0.3643\n",
      "Adjusting learning rate of group 0 to 2.5000e-02.\n",
      "Train:\tAverage Loss: -0.3903,\tAccuracy: 99.95%,\tCosine: 0.3944,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5377,\tAccuracy: 94.74%,\tValidation Margin: -0.2954\n",
      "Adjusting learning rate of group 0 to 2.4738e-02.\n",
      "Train:\tAverage Loss: -0.3947,\tAccuracy: 99.96%,\tCosine: 0.3975,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5425,\tAccuracy: 94.69%,\tValidation Margin: -0.2788\n",
      "Adjusting learning rate of group 0 to 2.4476e-02.\n",
      "Train:\tAverage Loss: -0.3949,\tAccuracy: 99.94%,\tCosine: 0.3991,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5622,\tAccuracy: 94.47%,\tValidation Margin: -0.3939\n",
      "Adjusting learning rate of group 0 to 2.4215e-02.\n",
      "Train:\tAverage Loss: -0.3971,\tAccuracy: 99.95%,\tCosine: 0.4004,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5363,\tAccuracy: 94.62%,\tValidation Margin: -0.3318\n",
      "Adjusting learning rate of group 0 to 2.3953e-02.\n",
      "Train:\tAverage Loss: -0.4002,\tAccuracy: 99.95%,\tCosine: 0.4040,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5374,\tAccuracy: 94.95%,\tValidation Margin: -0.0536\n",
      "Adjusting learning rate of group 0 to 2.3692e-02.\n",
      "Train:\tAverage Loss: -0.4021,\tAccuracy: 99.96%,\tCosine: 0.4053,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5606,\tAccuracy: 94.47%,\tValidation Margin: -0.4142\n",
      "Adjusting learning rate of group 0 to 2.3430e-02.\n",
      "Train:\tAverage Loss: -0.4031,\tAccuracy: 99.95%,\tCosine: 0.4071,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5830,\tAccuracy: 94.68%,\tValidation Margin: -0.2876\n",
      "Adjusting learning rate of group 0 to 2.3169e-02.\n",
      "Train:\tAverage Loss: -0.4055,\tAccuracy: 99.94%,\tCosine: 0.4097,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5440,\tAccuracy: 94.72%,\tValidation Margin: -0.2387\n",
      "Adjusting learning rate of group 0 to 2.2908e-02.\n",
      "Train:\tAverage Loss: -0.4034,\tAccuracy: 99.92%,\tCosine: 0.4085,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5631,\tAccuracy: 94.61%,\tValidation Margin: -0.3103\n",
      "Adjusting learning rate of group 0 to 2.2647e-02.\n",
      "Train:\tAverage Loss: -0.4058,\tAccuracy: 99.94%,\tCosine: 0.4104,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5577,\tAccuracy: 94.86%,\tValidation Margin: -0.1437\n",
      "Adjusting learning rate of group 0 to 2.2387e-02.\n",
      "Train:\tAverage Loss: -0.4112,\tAccuracy: 99.93%,\tCosine: 0.4149,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5576,\tAccuracy: 94.77%,\tValidation Margin: -0.2514\n",
      "Adjusting learning rate of group 0 to 2.2127e-02.\n",
      "Train:\tAverage Loss: -0.4125,\tAccuracy: 99.95%,\tCosine: 0.4161,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5676,\tAccuracy: 94.62%,\tValidation Margin: -0.3415\n",
      "Adjusting learning rate of group 0 to 2.1867e-02.\n",
      "Train:\tAverage Loss: -0.4141,\tAccuracy: 99.94%,\tCosine: 0.4185,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5541,\tAccuracy: 94.85%,\tValidation Margin: -0.1508\n",
      "Adjusting learning rate of group 0 to 2.1607e-02.\n",
      "Train:\tAverage Loss: -0.4168,\tAccuracy: 99.95%,\tCosine: 0.4200,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5572,\tAccuracy: 94.67%,\tValidation Margin: -0.2552\n",
      "Adjusting learning rate of group 0 to 2.1348e-02.\n",
      "Train:\tAverage Loss: -0.4194,\tAccuracy: 99.94%,\tCosine: 0.4235,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5890,\tAccuracy: 94.75%,\tValidation Margin: -0.2308\n",
      "Adjusting learning rate of group 0 to 2.1089e-02.\n",
      "Train:\tAverage Loss: -0.4206,\tAccuracy: 99.94%,\tCosine: 0.4247,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5665,\tAccuracy: 94.86%,\tValidation Margin: -0.2040\n",
      "Adjusting learning rate of group 0 to 2.0831e-02.\n",
      "Train:\tAverage Loss: -0.4260,\tAccuracy: 99.96%,\tCosine: 0.4286,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5753,\tAccuracy: 94.81%,\tValidation Margin: -0.2639\n",
      "Adjusting learning rate of group 0 to 2.0573e-02.\n",
      "Train:\tAverage Loss: -0.4289,\tAccuracy: 99.96%,\tCosine: 0.4315,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5653,\tAccuracy: 94.96%,\tValidation Margin: -0.0125\n",
      "Adjusting learning rate of group 0 to 2.0315e-02.\n",
      "Train:\tAverage Loss: -0.4313,\tAccuracy: 99.97%,\tCosine: 0.4337,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5818,\tAccuracy: 94.89%,\tValidation Margin: -0.1559\n",
      "Adjusting learning rate of group 0 to 2.0059e-02.\n",
      "Train:\tAverage Loss: -0.4322,\tAccuracy: 99.94%,\tCosine: 0.4362,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6189,\tAccuracy: 94.76%,\tValidation Margin: -0.2502\n",
      "Adjusting learning rate of group 0 to 1.9802e-02.\n",
      "Train:\tAverage Loss: -0.4308,\tAccuracy: 99.92%,\tCosine: 0.4365,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5865,\tAccuracy: 94.77%,\tValidation Margin: -0.2998\n",
      "Adjusting learning rate of group 0 to 1.9546e-02.\n",
      "Train:\tAverage Loss: -0.4360,\tAccuracy: 99.96%,\tCosine: 0.4392,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5718,\tAccuracy: 94.82%,\tValidation Margin: -0.1635\n",
      "Adjusting learning rate of group 0 to 1.9291e-02.\n",
      "Train:\tAverage Loss: -0.4396,\tAccuracy: 99.95%,\tCosine: 0.4431,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5957,\tAccuracy: 94.76%,\tValidation Margin: -0.2913\n",
      "Adjusting learning rate of group 0 to 1.9037e-02.\n",
      "Train:\tAverage Loss: -0.4407,\tAccuracy: 99.93%,\tCosine: 0.4447,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6128,\tAccuracy: 94.78%,\tValidation Margin: -0.2807\n",
      "Adjusting learning rate of group 0 to 1.8783e-02.\n",
      "Train:\tAverage Loss: -0.4439,\tAccuracy: 99.94%,\tCosine: 0.4474,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.5986,\tAccuracy: 94.63%,\tValidation Margin: -0.3292\n",
      "Adjusting learning rate of group 0 to 1.8530e-02.\n",
      "Train:\tAverage Loss: -0.4492,\tAccuracy: 99.97%,\tCosine: 0.4513,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6366,\tAccuracy: 94.43%,\tValidation Margin: -0.4519\n",
      "Adjusting learning rate of group 0 to 1.8277e-02.\n",
      "Train:\tAverage Loss: -0.4512,\tAccuracy: 99.97%,\tCosine: 0.4537,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6378,\tAccuracy: 94.77%,\tValidation Margin: -0.2477\n",
      "Adjusting learning rate of group 0 to 1.8025e-02.\n",
      "Train:\tAverage Loss: -0.4548,\tAccuracy: 99.97%,\tCosine: 0.4569,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6428,\tAccuracy: 94.52%,\tValidation Margin: -0.4969\n",
      "Adjusting learning rate of group 0 to 1.7774e-02.\n",
      "Train:\tAverage Loss: -0.4558,\tAccuracy: 99.95%,\tCosine: 0.4588,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6472,\tAccuracy: 94.56%,\tValidation Margin: -0.4262\n",
      "Adjusting learning rate of group 0 to 1.7524e-02.\n",
      "Train:\tAverage Loss: -0.4574,\tAccuracy: 99.95%,\tCosine: 0.4606,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6550,\tAccuracy: 94.52%,\tValidation Margin: -0.5038\n",
      "Adjusting learning rate of group 0 to 1.7275e-02.\n",
      "Train:\tAverage Loss: -0.4595,\tAccuracy: 99.96%,\tCosine: 0.4629,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6814,\tAccuracy: 94.64%,\tValidation Margin: -0.3965\n",
      "Adjusting learning rate of group 0 to 1.7026e-02.\n",
      "Train:\tAverage Loss: -0.4653,\tAccuracy: 99.96%,\tCosine: 0.4677,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6583,\tAccuracy: 94.79%,\tValidation Margin: -0.2116\n",
      "Adjusting learning rate of group 0 to 1.6778e-02.\n",
      "Train:\tAverage Loss: -0.4650,\tAccuracy: 99.96%,\tCosine: 0.4677,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7026,\tAccuracy: 94.57%,\tValidation Margin: -0.4738\n",
      "Adjusting learning rate of group 0 to 1.6532e-02.\n",
      "Train:\tAverage Loss: -0.4688,\tAccuracy: 99.96%,\tCosine: 0.4719,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6845,\tAccuracy: 94.92%,\tValidation Margin: -0.0988\n",
      "Adjusting learning rate of group 0 to 1.6286e-02.\n",
      "Train:\tAverage Loss: -0.4688,\tAccuracy: 99.94%,\tCosine: 0.4732,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6676,\tAccuracy: 94.83%,\tValidation Margin: -0.2112\n",
      "Adjusting learning rate of group 0 to 1.6041e-02.\n",
      "Train:\tAverage Loss: -0.4731,\tAccuracy: 99.94%,\tCosine: 0.4762,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6259,\tAccuracy: 94.69%,\tValidation Margin: -0.3345\n",
      "Adjusting learning rate of group 0 to 1.5797e-02.\n",
      "Train:\tAverage Loss: -0.4780,\tAccuracy: 99.96%,\tCosine: 0.4802,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6633,\tAccuracy: 94.95%,\tValidation Margin: -0.0366\n",
      "Adjusting learning rate of group 0 to 1.5554e-02.\n",
      "Train:\tAverage Loss: -0.4806,\tAccuracy: 99.96%,\tCosine: 0.4828,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6816,\tAccuracy: 94.69%,\tValidation Margin: -0.3395\n",
      "Adjusting learning rate of group 0 to 1.5312e-02.\n",
      "Train:\tAverage Loss: -0.4828,\tAccuracy: 99.95%,\tCosine: 0.4858,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6811,\tAccuracy: 95.07%,\tValidation Margin: 0.1145\n",
      "Adjusting learning rate of group 0 to 1.5071e-02.\n",
      "Train:\tAverage Loss: -0.4877,\tAccuracy: 99.98%,\tCosine: 0.4899,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6811,\tAccuracy: 95.00%,\tValidation Margin: 0.0012\n",
      "Adjusting learning rate of group 0 to 1.4832e-02.\n",
      "Train:\tAverage Loss: -0.4886,\tAccuracy: 99.95%,\tCosine: 0.4912,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6674,\tAccuracy: 94.93%,\tValidation Margin: -0.1270\n",
      "Adjusting learning rate of group 0 to 1.4593e-02.\n",
      "Train:\tAverage Loss: -0.4913,\tAccuracy: 99.96%,\tCosine: 0.4937,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6820,\tAccuracy: 94.79%,\tValidation Margin: -0.3089\n",
      "Adjusting learning rate of group 0 to 1.4356e-02.\n",
      "Train:\tAverage Loss: -0.4932,\tAccuracy: 99.96%,\tCosine: 0.4962,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6707,\tAccuracy: 95.00%,\tValidation Margin: 0.0203\n",
      "Adjusting learning rate of group 0 to 1.4119e-02.\n",
      "Train:\tAverage Loss: -0.4964,\tAccuracy: 99.95%,\tCosine: 0.4991,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6816,\tAccuracy: 94.92%,\tValidation Margin: -0.1504\n",
      "Adjusting learning rate of group 0 to 1.3884e-02.\n",
      "Train:\tAverage Loss: -0.4988,\tAccuracy: 99.96%,\tCosine: 0.5015,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7011,\tAccuracy: 94.90%,\tValidation Margin: -0.1234\n",
      "Adjusting learning rate of group 0 to 1.3650e-02.\n",
      "Train:\tAverage Loss: -0.5015,\tAccuracy: 99.94%,\tCosine: 0.5050,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6979,\tAccuracy: 94.74%,\tValidation Margin: -0.3313\n",
      "Adjusting learning rate of group 0 to 1.3418e-02.\n",
      "Train:\tAverage Loss: -0.5039,\tAccuracy: 99.96%,\tCosine: 0.5063,\tPSNR: 0.0000\n",
      "Train:\tAverage Loss: -0.5072,\tAccuracy: 99.96%,\tCosine: 0.5098,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7167,\tAccuracy: 94.76%,\tValidation Margin: -0.3523\n",
      "Adjusting learning rate of group 0 to 1.2956e-02.\n",
      "Train:\tAverage Loss: -0.5105,\tAccuracy: 99.96%,\tCosine: 0.5127,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7348,\tAccuracy: 94.96%,\tValidation Margin: -0.0972\n",
      "Adjusting learning rate of group 0 to 1.2727e-02.\n",
      "Train:\tAverage Loss: -0.5137,\tAccuracy: 99.97%,\tCosine: 0.5155,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7331,\tAccuracy: 94.63%,\tValidation Margin: -0.5099\n",
      "Adjusting learning rate of group 0 to 1.2500e-02.\n",
      "Train:\tAverage Loss: -0.5148,\tAccuracy: 99.96%,\tCosine: 0.5181,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7412,\tAccuracy: 94.71%,\tValidation Margin: -0.3858\n",
      "Adjusting learning rate of group 0 to 1.2274e-02.\n",
      "Train:\tAverage Loss: -0.5200,\tAccuracy: 99.97%,\tCosine: 0.5220,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7396,\tAccuracy: 94.92%,\tValidation Margin: -0.1699\n",
      "Adjusting learning rate of group 0 to 1.2049e-02.\n",
      "Train:\tAverage Loss: -0.5216,\tAccuracy: 99.98%,\tCosine: 0.5235,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7418,\tAccuracy: 94.85%,\tValidation Margin: -0.1443\n",
      "Adjusting learning rate of group 0 to 1.1826e-02.\n",
      "Train:\tAverage Loss: -0.5257,\tAccuracy: 99.97%,\tCosine: 0.5275,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7623,\tAccuracy: 94.68%,\tValidation Margin: -0.3412\n",
      "Adjusting learning rate of group 0 to 1.1604e-02.\n",
      "Train:\tAverage Loss: -0.5253,\tAccuracy: 99.96%,\tCosine: 0.5280,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7454,\tAccuracy: 94.83%,\tValidation Margin: -0.2844\n",
      "Adjusting learning rate of group 0 to 1.1384e-02.\n",
      "Train:\tAverage Loss: -0.5284,\tAccuracy: 99.96%,\tCosine: 0.5311,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7206,\tAccuracy: 94.88%,\tValidation Margin: -0.2053\n",
      "Adjusting learning rate of group 0 to 1.1165e-02.\n",
      "Train:\tAverage Loss: -0.5319,\tAccuracy: 99.96%,\tCosine: 0.5343,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.6971,\tAccuracy: 95.16%,\tValidation Margin: 0.2165\n",
      "Adjusting learning rate of group 0 to 1.0948e-02.\n",
      "Train:\tAverage Loss: -0.5357,\tAccuracy: 99.98%,\tCosine: 0.5374,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7702,\tAccuracy: 94.82%,\tValidation Margin: -0.2500\n",
      "Adjusting learning rate of group 0 to 1.0732e-02.\n",
      "Train:\tAverage Loss: -0.5376,\tAccuracy: 99.98%,\tCosine: 0.5395,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7581,\tAccuracy: 94.82%,\tValidation Margin: -0.2429\n",
      "Adjusting learning rate of group 0 to 1.0518e-02.\n",
      "Train:\tAverage Loss: -0.5406,\tAccuracy: 99.97%,\tCosine: 0.5427,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7129,\tAccuracy: 94.98%,\tValidation Margin: -0.0092\n",
      "Adjusting learning rate of group 0 to 1.0305e-02.\n",
      "Train:\tAverage Loss: -0.5408,\tAccuracy: 99.97%,\tCosine: 0.5435,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7340,\tAccuracy: 94.81%,\tValidation Margin: -0.2614\n",
      "Adjusting learning rate of group 0 to 1.0094e-02.\n",
      "Train:\tAverage Loss: -0.5467,\tAccuracy: 99.97%,\tCosine: 0.5488,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7234,\tAccuracy: 94.76%,\tValidation Margin: -0.3370\n",
      "Adjusting learning rate of group 0 to 9.8850e-03.\n",
      "Train:\tAverage Loss: -0.5490,\tAccuracy: 99.98%,\tCosine: 0.5505,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7391,\tAccuracy: 94.88%,\tValidation Margin: -0.1908\n",
      "Adjusting learning rate of group 0 to 9.6773e-03.\n",
      "Train:\tAverage Loss: -0.5501,\tAccuracy: 99.97%,\tCosine: 0.5524,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7584,\tAccuracy: 94.80%,\tValidation Margin: -0.3121\n",
      "Adjusting learning rate of group 0 to 9.4713e-03.\n",
      "Train:\tAverage Loss: -0.5526,\tAccuracy: 99.98%,\tCosine: 0.5544,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7855,\tAccuracy: 94.54%,\tValidation Margin: -0.5353\n",
      "Adjusting learning rate of group 0 to 9.2670e-03.\n",
      "Train:\tAverage Loss: -0.5561,\tAccuracy: 99.98%,\tCosine: 0.5582,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7618,\tAccuracy: 94.84%,\tValidation Margin: -0.2421\n",
      "Adjusting learning rate of group 0 to 9.0644e-03.\n",
      "Train:\tAverage Loss: -0.5600,\tAccuracy: 99.97%,\tCosine: 0.5618,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7620,\tAccuracy: 94.58%,\tValidation Margin: -0.5026\n",
      "Adjusting learning rate of group 0 to 8.8636e-03.\n",
      "Train:\tAverage Loss: -0.5635,\tAccuracy: 99.98%,\tCosine: 0.5651,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7595,\tAccuracy: 94.87%,\tValidation Margin: -0.1801\n",
      "Adjusting learning rate of group 0 to 8.6645e-03.\n",
      "Train:\tAverage Loss: -0.5661,\tAccuracy: 99.99%,\tCosine: 0.5674,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7868,\tAccuracy: 94.85%,\tValidation Margin: -0.2369\n",
      "Adjusting learning rate of group 0 to 8.4672e-03.\n",
      "Train:\tAverage Loss: -0.5673,\tAccuracy: 99.98%,\tCosine: 0.5687,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7764,\tAccuracy: 94.75%,\tValidation Margin: -0.3579\n",
      "Adjusting learning rate of group 0 to 8.2717e-03.\n",
      "Train:\tAverage Loss: -0.5689,\tAccuracy: 99.98%,\tCosine: 0.5708,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.8084,\tAccuracy: 94.66%,\tValidation Margin: -0.4496\n",
      "Adjusting learning rate of group 0 to 8.0781e-03.\n",
      "Train:\tAverage Loss: -0.5693,\tAccuracy: 99.96%,\tCosine: 0.5715,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7743,\tAccuracy: 94.92%,\tValidation Margin: -0.1630\n",
      "Adjusting learning rate of group 0 to 7.8863e-03.\n",
      "Train:\tAverage Loss: -0.5738,\tAccuracy: 99.97%,\tCosine: 0.5756,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7931,\tAccuracy: 94.67%,\tValidation Margin: -0.4190\n",
      "Adjusting learning rate of group 0 to 7.6964e-03.\n",
      "Train:\tAverage Loss: -0.5744,\tAccuracy: 99.97%,\tCosine: 0.5762,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7825,\tAccuracy: 94.64%,\tValidation Margin: -0.4147\n",
      "Adjusting learning rate of group 0 to 7.5084e-03.\n",
      "Train:\tAverage Loss: -0.5774,\tAccuracy: 99.97%,\tCosine: 0.5795,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7626,\tAccuracy: 94.98%,\tValidation Margin: -0.0187\n",
      "Adjusting learning rate of group 0 to 7.3223e-03.\n",
      "Train:\tAverage Loss: -0.5791,\tAccuracy: 99.97%,\tCosine: 0.5809,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7987,\tAccuracy: 94.89%,\tValidation Margin: -0.1641\n",
      "Adjusting learning rate of group 0 to 7.1382e-03.\n",
      "Train:\tAverage Loss: -0.5833,\tAccuracy: 99.98%,\tCosine: 0.5853,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.8110,\tAccuracy: 94.73%,\tValidation Margin: -0.4202\n",
      "Adjusting learning rate of group 0 to 6.9560e-03.\n",
      "Train:\tAverage Loss: -0.5860,\tAccuracy: 99.98%,\tCosine: 0.5874,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7979,\tAccuracy: 94.88%,\tValidation Margin: -0.2004\n",
      "Adjusting learning rate of group 0 to 6.7758e-03.\n",
      "Train:\tAverage Loss: -0.5867,\tAccuracy: 99.97%,\tCosine: 0.5885,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.8075,\tAccuracy: 94.65%,\tValidation Margin: -0.5030\n",
      "Adjusting learning rate of group 0 to 6.5976e-03.\n",
      "Train:\tAverage Loss: -0.5913,\tAccuracy: 99.98%,\tCosine: 0.5929,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7902,\tAccuracy: 94.79%,\tValidation Margin: -0.4012\n",
      "Adjusting learning rate of group 0 to 6.4214e-03.\n",
      "Train:\tAverage Loss: -0.5922,\tAccuracy: 99.98%,\tCosine: 0.5937,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.8129,\tAccuracy: 94.77%,\tValidation Margin: -0.3105\n",
      "Adjusting learning rate of group 0 to 6.2472e-03.\n",
      "Train:\tAverage Loss: -0.5937,\tAccuracy: 99.98%,\tCosine: 0.5953,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.8184,\tAccuracy: 94.74%,\tValidation Margin: -0.3525\n",
      "Adjusting learning rate of group 0 to 6.0751e-03.\n",
      "Train:\tAverage Loss: -0.5954,\tAccuracy: 99.98%,\tCosine: 0.5969,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.8073,\tAccuracy: 94.98%,\tValidation Margin: -0.0463\n",
      "Adjusting learning rate of group 0 to 5.9051e-03.\n",
      "Train:\tAverage Loss: -0.5983,\tAccuracy: 99.98%,\tCosine: 0.6001,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.8155,\tAccuracy: 94.90%,\tValidation Margin: -0.1376\n",
      "Adjusting learning rate of group 0 to 5.7372e-03.\n",
      "Train:\tAverage Loss: -0.5999,\tAccuracy: 99.98%,\tCosine: 0.6015,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7948,\tAccuracy: 94.78%,\tValidation Margin: -0.3963\n",
      "Adjusting learning rate of group 0 to 5.5714e-03.\n",
      "Train:\tAverage Loss: -0.6026,\tAccuracy: 99.98%,\tCosine: 0.6040,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7871,\tAccuracy: 95.01%,\tValidation Margin: 0.0122\n",
      "Adjusting learning rate of group 0 to 5.4077e-03.\n",
      "Train:\tAverage Loss: -0.6049,\tAccuracy: 99.99%,\tCosine: 0.6062,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.8047,\tAccuracy: 94.80%,\tValidation Margin: -0.3096\n",
      "Adjusting learning rate of group 0 to 5.2461e-03.\n",
      "Train:\tAverage Loss: -0.6068,\tAccuracy: 99.98%,\tCosine: 0.6082,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7740,\tAccuracy: 94.76%,\tValidation Margin: -0.4206\n",
      "Adjusting learning rate of group 0 to 5.0868e-03.\n",
      "Train:\tAverage Loss: -0.6093,\tAccuracy: 99.98%,\tCosine: 0.6109,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.8312,\tAccuracy: 94.70%,\tValidation Margin: -0.4598\n",
      "Adjusting learning rate of group 0 to 4.9296e-03.\n",
      "Train:\tAverage Loss: -0.6127,\tAccuracy: 99.99%,\tCosine: 0.6139,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7883,\tAccuracy: 94.81%,\tValidation Margin: -0.2600\n",
      "Adjusting learning rate of group 0 to 4.7746e-03.\n",
      "Train:\tAverage Loss: -0.6131,\tAccuracy: 99.99%,\tCosine: 0.6144,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7977,\tAccuracy: 94.75%,\tValidation Margin: -0.3632\n",
      "Adjusting learning rate of group 0 to 4.6218e-03.\n",
      "Train:\tAverage Loss: -0.6138,\tAccuracy: 99.98%,\tCosine: 0.6154,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.8183,\tAccuracy: 94.77%,\tValidation Margin: -0.3495\n",
      "Adjusting learning rate of group 0 to 4.4713e-03.\n",
      "Train:\tAverage Loss: -0.6157,\tAccuracy: 99.98%,\tCosine: 0.6174,\tPSNR: 0.0000\n",
      "Test:\tAverage Loss: 0.7736,\tAccuracy: 94.84%,\tValidation Margin: -0.2810\n",
      "Adjusting learning rate of group 0 to 4.3230e-03.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "device = \"cuda:0\"\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "\n",
    "train_loss, train_acc = [], []\n",
    "valid_loss, valid_acc = [], []\n",
    "margin, cosine = [], []\n",
    "best_val_loss = 0.0\n",
    "\n",
    "# Train network\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "#     newlr = utils.swa_schedule(epoch, lr_init=lr)\n",
    "#     for group in opt.param_groups:\n",
    "#         group['lr'] = newlr\n",
    "#         print(\"new learning rate: \", newlr)\n",
    "    \n",
    "    tr_loss, tr_acc, cos, psnr = train_cosine(model, opt, train_loader, criterion, device)\n",
    "    train_loss.append(tr_loss), train_acc.append(tr_acc), cosine.append(cos)\n",
    "    print(\"Train:\\tAverage Loss: {:.4f},\\tAccuracy: {:.2f}%,\\tCosine: {:.4f},\\tPSNR: {:.4f}\".format(tr_loss, 100.0 * tr_acc, cos, psnr))\n",
    "    \n",
    "    val_loss, val_acc, val_margin, _ = utils.test(model, valid_loader, criterion, device)\n",
    "    valid_loss.append(val_loss), valid_acc.append(val_acc), margin.append(val_margin)\n",
    "    print(\"Test:\\tAverage Loss: {:.4f},\\tAccuracy: {:.2f}%,\\tValidation Margin: {:.4f}\".format(val_loss, 100.0 * val_acc, val_margin))\n",
    "    \n",
    "    # Get bool not ByteTensor\n",
    "    is_best = True if epoch == 0 else bool(val_loss < best_val_loss)\n",
    "    # Get greater Tensor to keep track best acc\n",
    "    operator = max if epoch == 0 else min\n",
    "    best_val_loss = torch.FloatTensor([operator(val_loss, best_val_loss)])\n",
    "    # Save checkpoint if is a new best\n",
    "    utils.save_checkpoint({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optim_state_dict': opt.state_dict(),\n",
    "        'valid_accuracy': valid_acc\n",
    "    }, is_best, val_acc, filename='./checkpoints/alternative/wideres28x10_drop_svhn_xent_cosine_ood_cifar10.pth.tar')\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05af640",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6382f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=256\n",
    "min_valid_loss = min(valid_loss)\n",
    "best_epoch, = np.where(np.array(valid_loss) == min_valid_loss)\n",
    "max_valid_acc = valid_acc[best_epoch.item()]\n",
    "%matplotlib inline\n",
    "plt.plot(range(epochs), train_loss, label='train loss')\n",
    "plt.plot(range(epochs), train_acc, label='train acc')\n",
    "plt.plot(range(epochs), valid_loss, label='valid loss')\n",
    "plt.plot(range(epochs), valid_acc, label='valid acc')\n",
    "plt.plot(range(epochs), margin, label='margin')\n",
    "plt.vlines(best_epoch.item(), ymin=min_valid_loss, ymax=max_valid_acc, colors='black', label='best-valid@{:.2f}%'.format(100.0 * max_valid_acc))\n",
    "plt.title(\"Loss vs Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt = torch.load('./checkpoints/baseline/allconv_svhn.pth.tar')\n",
    "model.load_state_dict(chkpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3cc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss, acc, te_margin, logits_in = utils.test(model, test_loader, criterion, device)\n",
    "print(\"Test:\\tAverage Loss: {:.4f},\\tAccuracy: {:.2f}%,\\tMargin: {:.4f}\".format(loss, 100.0 * acc, te_margin))\n",
    "loss, acc, ood_margin, logits_out = utils.test(model, cifar100_test, criterion, device, ood=True)\n",
    "print(\"Test OoD:\\tAverage Loss: {:.4f},\\tAccuracy: {:.2f}%,\\tMaring: {:.4f}\".format(loss, 100.0 * acc, ood_margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af2c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_in = torch.vstack(logits_in)\n",
    "logits_out = torch.vstack(logits_out)\n",
    "metrics_in = metrics.dirichlet_uncertainty(logits_in.cpu().numpy())\n",
    "metrics_out = metrics.dirichlet_uncertainty(logits_out.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cdf5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = len(logits_in)\n",
    "y_ood = len(logits_out)\n",
    "for string in ['confidence', 'entropy_of_conf', 'mutual_information']:\n",
    "    if string == \"confidence\":\n",
    "        y_true = np.r_[np.ones(y_test), np.zeros(y_ood)]\n",
    "        y_scores = np.r_[metrics_in[string], metrics_out[string]]\n",
    "    else:\n",
    "        y_true = np.r_[np.ones(y_ood), np.zeros(y_test)]\n",
    "        y_scores = np.r_[metrics_out[string], metrics_in[string]]\n",
    "    print(\"ROC values:\\n {} = {},\\n\".format(string, roc_auc_score(y_true, y_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "f, ax = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "for i, string in enumerate(['confidence', 'entropy_of_conf', 'mutual_information']):\n",
    "#     ax[i].set_xscale('log')\n",
    "    ax[i].hist(metrics_in[string], bins=np.linspace(0, 3, num=10), label='Test', alpha=0.5)\n",
    "    ax[i].hist(metrics_out[string], bins=np.linspace(0, 3, num=10), label='OoD', alpha=0.5)\n",
    "    ax[i].legend()\n",
    "    ax[i].set_title(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_loader))\n",
    "X, y = X.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ef0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# model.to(device)\n",
    "model.eval()\n",
    "Xi, Yi, Zi = utils.draw_loss(model, X[0:1], y[0:1], device=device)\n",
    "plots.plot_loss(Xi, Yi, Zi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421056c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
